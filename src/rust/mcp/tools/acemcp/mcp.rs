use anyhow::Result;
use rmcp::{model::*, Error as McpError};
use std::borrow::Cow;
use std::collections::HashMap;
use std::fs;
use std::io::Read;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Duration;

use reqwest::header::{AUTHORIZATION, CONTENT_TYPE};
use reqwest::Client;
use ring::digest::{Context as ShaContext, SHA256};
use ignore::gitignore::{Gitignore, GitignoreBuilder};
use serde::{Deserialize, Serialize};
use encoding_rs::{GBK, WINDOWS_1252, UTF_8};
use globset::{Glob, GlobSet, GlobSetBuilder};

use super::types::{AcemcpRequest, AcemcpConfig, ProjectIndexStatus, ProjectsIndexStatus, IndexStatus};
use crate::log_debug;
use crate::log_important;

/// Acemcpå·¥å…·å®ç°
pub struct AcemcpTool;

impl AcemcpTool {
    /// æ‰§è¡Œä»£ç åº“æœç´¢ï¼ˆä»…æœç´¢ï¼Œä¸è§¦å‘ç´¢å¼•ï¼‰
    pub async fn search_context(request: AcemcpRequest) -> Result<CallToolResult, McpError> {
        log_important!(info,
            "Acemcpæœç´¢è¯·æ±‚ï¼ˆä»…æœç´¢æ¨¡å¼ï¼‰: project_root_path={}, query={}",
            request.project_root_path, request.query
        );

        // è¯»å–é…ç½®
        let mut acemcp_config = Self::get_acemcp_config()
            .await
            .map_err(|e| McpError::internal_error(format!("è·å–acemcpé…ç½®å¤±è´¥: {}", e), None))?;

        // è§„èŒƒåŒ– base_urlï¼ˆç¼ºåè®®æ—¶è¡¥ http://ï¼‰ï¼Œå¹¶å»é™¤æœ«å°¾æ–œæ 
        if let Some(base) = &acemcp_config.base_url {
            let normalized = normalize_base_url(base);
            acemcp_config.base_url = Some(normalized);
        }

        // é¦–æ¬¡æœç´¢æ—¶è‡ªåŠ¨å¯åŠ¨æ–‡ä»¶ç›‘å¬ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
        let watcher_manager = super::watcher::get_watcher_manager();
        if !watcher_manager.is_watching(&request.project_root_path) {
            log_debug!("é¦–æ¬¡æœç´¢ï¼Œå°è¯•å¯åŠ¨æ–‡ä»¶ç›‘å¬");
            if let Err(e) = watcher_manager.start_watching(
                request.project_root_path.clone(),
                acemcp_config.clone()
            ).await {
                log_debug!("å¯åŠ¨æ–‡ä»¶ç›‘å¬å¤±è´¥ï¼ˆä¸å½±å“æœç´¢ï¼‰: {}", e);
            }
        }

        // 1. æ£€æŸ¥åˆå§‹ç´¢å¼•çŠ¶æ€
        let initial_state = get_initial_index_state(&request.project_root_path);
        log_debug!("é¡¹ç›®ç´¢å¼•çŠ¶æ€: {:?}", initial_state);

        // 2. æ ¹æ®çŠ¶æ€æ‰§è¡Œç›¸åº”æ“ä½œ
        let mut hint_message = String::new();
        match initial_state {
            InitialIndexState::Missing | InitialIndexState::Idle | InitialIndexState::Failed => {
                // å¯åŠ¨åå°ç´¢å¼•
                if let Err(e) = ensure_initial_index_background(&acemcp_config, &request.project_root_path).await {
                    log_debug!("å¯åŠ¨åå°ç´¢å¼•å¤±è´¥ï¼ˆä¸å½±å“æœç´¢ï¼‰: {}", e);
                } else {
                    hint_message = "\n\nğŸ’¡ æç¤ºï¼šå½“å‰é¡¹ç›®ç´¢å¼•å°šæœªå®Œå…¨åˆå§‹åŒ–ï¼Œå·²åœ¨åå°å¯åŠ¨ç´¢å¼•ï¼Œç¨åæœç´¢ç»“æœä¼šæ›´å®Œæ•´ã€‚".to_string();
                }
            }
            InitialIndexState::Indexing => {
                // æ­£åœ¨ç´¢å¼•ä¸­ï¼Œåº”ç”¨æ™ºèƒ½ç­‰å¾…
                if let Some((min_wait, max_wait)) = acemcp_config.smart_wait_range {
                    use rand::Rng;
                    let wait_secs = rand::thread_rng().gen_range(min_wait..=max_wait);

                    log_important!(info, "æ£€æµ‹åˆ°ç´¢å¼•æ­£åœ¨è¿›è¡Œä¸­ï¼Œæ™ºèƒ½ç­‰å¾… {} ç§’åæ‰§è¡Œæœç´¢", wait_secs);
                    tokio::time::sleep(tokio::time::Duration::from_secs(wait_secs)).await;

                    hint_message = format!("\n\nğŸ’¡ æç¤ºï¼šæ£€æµ‹åˆ°ç´¢å¼•æ­£åœ¨è¿›è¡Œä¸­ï¼Œå·²ç­‰å¾… {} ç§’ä»¥è·å–æ›´å®Œæ•´çš„æœç´¢ç»“æœã€‚", wait_secs);
                }
            }
            InitialIndexState::Synced => {
                // å·²å®Œæˆç´¢å¼•ï¼Œç›´æ¥æœç´¢
                log_debug!("é¡¹ç›®ç´¢å¼•å·²å®Œæˆï¼Œç›´æ¥æ‰§è¡Œæœç´¢");
            }
        }

        // 3. æ‰§è¡Œæœç´¢ï¼ˆä¸è§¦å‘ç´¢å¼•ï¼‰
        let search_result = match search_only(&acemcp_config, &request.project_root_path, &request.query).await {
            Ok(text) => text,
            Err(e) => {
                return Ok(CallToolResult {
                    content: vec![Content::text(format!("Acemcpæœç´¢å¤±è´¥: {}", e))],
                    is_error: Some(true)
                });
            }
        };

        // 4. é™„åŠ æç¤ºä¿¡æ¯
        let final_result = if hint_message.is_empty() {
            search_result
        } else {
            format!("{}{}", search_result, hint_message)
        };

        Ok(CallToolResult { content: vec![Content::text(final_result)], is_error: None })
    }

    /// æ‰§è¡Œç´¢å¼•æ›´æ–°ï¼ˆå‘åå…¼å®¹çš„ç´¢å¼•+æœç´¢ä¸€ä½“åŒ–æ¥å£ï¼‰
    pub async fn index_and_search_legacy(request: AcemcpRequest) -> Result<CallToolResult, McpError> {
        log_important!(info,
            "Acemcpç´¢å¼•+æœç´¢è¯·æ±‚ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰: project_root_path={}, query={}",
            request.project_root_path, request.query
        );

        // è¯»å–é…ç½®
        let mut acemcp_config = Self::get_acemcp_config()
            .await
            .map_err(|e| McpError::internal_error(format!("è·å–acemcpé…ç½®å¤±è´¥: {}", e), None))?;

        // è§„èŒƒåŒ– base_urlï¼ˆç¼ºåè®®æ—¶è¡¥ http://ï¼‰ï¼Œå¹¶å»é™¤æœ«å°¾æ–œæ 
        if let Some(base) = &acemcp_config.base_url {
            let normalized = normalize_base_url(base);
            acemcp_config.base_url = Some(normalized);
        }

        // å…ˆæ‰§è¡Œç´¢å¼•æ›´æ–°
        match update_index(&acemcp_config, &request.project_root_path).await {
            Ok(_blob_names) => {
                // ç´¢å¼•æˆåŠŸåæ‰§è¡Œæœç´¢
                match search_only(&acemcp_config, &request.project_root_path, &request.query).await {
                    Ok(text) => Ok(CallToolResult { content: vec![Content::text(text)], is_error: None }),
                    Err(e) => Ok(CallToolResult { content: vec![Content::text(format!("æœç´¢å¤±è´¥: {}", e))], is_error: Some(true) })
                }
            }
            Err(e) => Ok(CallToolResult { content: vec![Content::text(format!("ç´¢å¼•æ›´æ–°å¤±è´¥: {}", e))], is_error: Some(true) })
        }
    }

    /// æ‰‹åŠ¨è§¦å‘ç´¢å¼•æ›´æ–°ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub async fn trigger_index_update(project_root_path: String) -> Result<String> {
        log_important!(info, "æ‰‹åŠ¨è§¦å‘ç´¢å¼•æ›´æ–°: project_root_path={}", project_root_path);

        let acemcp_config = Self::get_acemcp_config().await?;

        match update_index(&acemcp_config, &project_root_path).await {
            Ok(blob_names) => {
                Ok(format!("ç´¢å¼•æ›´æ–°æˆåŠŸï¼Œå…± {} ä¸ª blobs", blob_names.len()))
            }
            Err(e) => {
                Err(anyhow::anyhow!("ç´¢å¼•æ›´æ–°å¤±è´¥: {}", e))
            }
        }
    }

    /// è·å–é¡¹ç›®ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub fn get_index_status(project_root_path: String) -> ProjectIndexStatus {
        get_project_status(&project_root_path)
    }

    /// è·å–æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub fn get_all_index_status() -> ProjectsIndexStatus {
        load_projects_status()
    }

    /// è·å–acemcpé…ç½®
    async fn get_acemcp_config() -> Result<AcemcpConfig> {
        // ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–acemcpé…ç½®
        let config = crate::config::load_standalone_config()
            .map_err(|e| anyhow::anyhow!("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {}", e))?;

        Ok(AcemcpConfig {
            base_url: config.mcp_config.acemcp_base_url,
            token: config.mcp_config.acemcp_token,
            batch_size: config.mcp_config.acemcp_batch_size,
            max_lines_per_blob: config.mcp_config.acemcp_max_lines_per_blob,
            text_extensions: config.mcp_config.acemcp_text_extensions,
            exclude_patterns: config.mcp_config.acemcp_exclude_patterns,
            // æ™ºèƒ½ç­‰å¾…é»˜è®¤å€¼ï¼š1-5 ç§’éšæœºç­‰å¾…
            smart_wait_range: Some((1, 5)),
        })
    }

    /// è·å–å·¥å…·å®šä¹‰
    pub fn get_tool_definition() -> Tool {
        let schema = serde_json::json!({
            "type": "object",
            "properties": {
                "project_root_path": {
                    "type": "string",
                    "description": "é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œä½¿ç”¨æ­£æ–œæ (/)ä½œä¸ºåˆ†éš”ç¬¦ã€‚ä¾‹å¦‚ï¼šC:/Users/username/projects/myproject"
                },
                "query": {
                    "type": "string",
                    "description": "ç”¨äºæŸ¥æ‰¾ç›¸å…³ä»£ç ä¸Šä¸‹æ–‡çš„è‡ªç„¶è¯­è¨€æœç´¢æŸ¥è¯¢ã€‚æ­¤å·¥å…·æ‰§è¡Œè¯­ä¹‰æœç´¢å¹¶è¿”å›ä¸æŸ¥è¯¢åŒ¹é…çš„ä»£ç ç‰‡æ®µã€‚ä¾‹å¦‚ï¼š'æ—¥å¿—é…ç½®è®¾ç½®åˆå§‹åŒ–logger'ï¼ˆæŸ¥æ‰¾æ—¥å¿—è®¾ç½®ä»£ç ï¼‰ã€'ç”¨æˆ·è®¤è¯ç™»å½•'ï¼ˆæŸ¥æ‰¾è®¤è¯ç›¸å…³ä»£ç ï¼‰ã€'æ•°æ®åº“è¿æ¥æ± 'ï¼ˆæŸ¥æ‰¾æ•°æ®åº“è¿æ¥ä»£ç ï¼‰ã€'é”™è¯¯å¤„ç†å¼‚å¸¸'ï¼ˆæŸ¥æ‰¾é”™è¯¯å¤„ç†æ¨¡å¼ï¼‰ã€'APIç«¯ç‚¹è·¯ç”±'ï¼ˆæŸ¥æ‰¾APIè·¯ç”±å®šä¹‰ï¼‰ã€‚å·¥å…·è¿”å›å¸¦æœ‰æ–‡ä»¶è·¯å¾„å’Œè¡Œå·çš„æ ¼å¼åŒ–æ–‡æœ¬ç‰‡æ®µï¼Œæ˜¾ç¤ºç›¸å…³ä»£ç çš„ä½ç½®ã€‚"
                }
            },
            "required": ["project_root_path", "query"]
        });

        if let serde_json::Value::Object(schema_map) = schema {
            Tool {
                name: Cow::Borrowed("sou"),
                description: Some(Cow::Borrowed("åŸºäºæŸ¥è¯¢åœ¨ç‰¹å®šé¡¹ç›®ä¸­æœç´¢ç›¸å…³çš„ä»£ç ä¸Šä¸‹æ–‡ã€‚ä¾èµ–åå°å¢é‡ç´¢å¼•ä¸æ–‡ä»¶ç›‘å¬æœºåˆ¶ç»´æŠ¤ç´¢å¼•ï¼Œå¹¶åœ¨ç´¢å¼•è¿›è¡Œä¸­é€šè¿‡æ™ºèƒ½ç­‰å¾…åœ¨å®æ—¶æ€§å’Œå“åº”é€Ÿåº¦ä¹‹é—´åšå¹³è¡¡ã€‚è¿”å›ä»£ç åº“ä¸­ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸å…³çš„æ ¼å¼åŒ–æ–‡æœ¬ç‰‡æ®µã€‚")),
                input_schema: Arc::new(schema_map),
                annotations: None,
            }
        } else {
            panic!("Schema creation failed");
        }
    }
}

// ---------------- å·²ç§»é™¤ Python Web æœåŠ¡ä¾èµ–ï¼Œå®Œå…¨ä½¿ç”¨ Rust å®ç° ----------------

// ---------------- ç´¢å¼•åˆå§‹åŒ–çŠ¶æ€æšä¸¾ ----------------

/// ç´¢å¼•åˆå§‹åŒ–çŠ¶æ€
#[derive(Debug, Clone, PartialEq)]
pub enum InitialIndexState {
    /// é¡¹ç›®è®°å½•ä¸å­˜åœ¨
    Missing,
    /// ä»æœªç´¢å¼•è¿‡ï¼ˆçŠ¶æ€ä¸º Idle ä¸” total_files == 0ï¼‰
    Idle,
    /// å·²å®Œæˆç´¢å¼•
    Synced,
    /// æ­£åœ¨ç´¢å¼•ä¸­
    Indexing,
    /// ä¸Šæ¬¡ç´¢å¼•å¤±è´¥
    Failed,
}

/// è·å–é¡¹ç›®çš„åˆå§‹ç´¢å¼•çŠ¶æ€
pub fn get_initial_index_state(project_root: &str) -> InitialIndexState {
    let status = get_project_status(project_root);

    match status.status {
        IndexStatus::Idle if status.total_files == 0 => InitialIndexState::Idle,
        IndexStatus::Idle => InitialIndexState::Missing,
        IndexStatus::Synced => InitialIndexState::Synced,
        IndexStatus::Indexing => InitialIndexState::Indexing,
        IndexStatus::Failed => InitialIndexState::Failed,
    }
}

/// ç¡®ä¿åå°ç´¢å¼•å·²å¯åŠ¨ï¼ˆéé˜»å¡ï¼‰
/// ä»…åœ¨é¡¹ç›®æœªåˆå§‹åŒ–æˆ–ç´¢å¼•å¤±è´¥æ—¶å¯åŠ¨åå°ç´¢å¼•ä»»åŠ¡
pub async fn ensure_initial_index_background(config: &AcemcpConfig, project_root: &str) -> anyhow::Result<()> {
    let state = get_initial_index_state(project_root);

    match state {
        InitialIndexState::Missing | InitialIndexState::Idle | InitialIndexState::Failed => {
            // åœ¨åå°å¯åŠ¨ç´¢å¼•ä»»åŠ¡
            let config_clone = config.clone();
            let project_root_clone = project_root.to_string();

            tokio::spawn(async move {
                log_important!(info, "åå°ç´¢å¼•ä»»åŠ¡å¯åŠ¨: project_root={}", project_root_clone);
                if let Err(e) = update_index(&config_clone, &project_root_clone).await {
                    log_important!(info, "åå°ç´¢å¼•å¤±è´¥: project_root={}, error={}", project_root_clone, e);
                } else {
                    log_important!(info, "åå°ç´¢å¼•æˆåŠŸ: project_root={}", project_root_clone);
                }
            });

            Ok(())
        }
        InitialIndexState::Synced | InitialIndexState::Indexing => {
            // å·²ç»å®Œæˆæˆ–æ­£åœ¨è¿›è¡Œï¼Œæ— éœ€æ“ä½œ
            Ok(())
        }
    }
}

// ---------------- æ•´åˆ temp é€»è¾‘ï¼šç´¢å¼•ã€ä¸Šä¼ ã€æ£€ç´¢ ----------------

#[derive(Serialize, Deserialize, Clone)]
struct BlobItem {
    path: String,
    content: String,
}

#[derive(Serialize, Deserialize, Default)]
struct ProjectsFile(HashMap<String, Vec<String>>);

fn normalize_base_url(input: &str) -> String {
    let mut url = input.trim().to_string();
    if !(url.starts_with("http://") || url.starts_with("https://")) {
        url = format!("http://{}", url);
    }
    while url.ends_with('/') { url.pop(); }
    url
}

async fn retry_request<F, Fut, T>(mut f: F, max_retries: usize, base_delay_secs: f64) -> anyhow::Result<T>
where
    F: FnMut() -> Fut,
    Fut: std::future::Future<Output = anyhow::Result<T>>,
{
    let mut attempt = 0usize;
    let mut last_error_str: Option<String> = None;
    
    while attempt < max_retries {
        match f().await {
            Ok(v) => {
                if attempt > 0 {
                    log_debug!("è¯·æ±‚åœ¨ç¬¬{}æ¬¡å°è¯•åæˆåŠŸ", attempt + 1);
                }
                return Ok(v);
            }
            Err(e) => {
                last_error_str = Some(e.to_string());
                attempt += 1;
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
                let error_str = e.to_string();
                let is_retryable = error_str.contains("timeout") 
                    || error_str.contains("connection") 
                    || error_str.contains("network")
                    || error_str.contains("temporary");
                
                if attempt >= max_retries || !is_retryable {
                    log_debug!("è¯·æ±‚å¤±è´¥ï¼Œä¸å†é‡è¯•: {}", e);
                    return Err(e);
                }
                
                let delay = base_delay_secs * 2f64.powi((attempt as i32) - 1);
                let ms = (delay * 1000.0) as u64;
                log_debug!("è¯·æ±‚å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•({}/{}), ç­‰å¾… {}ms: {}", attempt, max_retries, ms, e);
                tokio::time::sleep(Duration::from_millis(ms)).await;
            }
        }
    }
    
    Err(last_error_str
        .and_then(|s| anyhow::anyhow!(s).into())
        .unwrap_or_else(|| anyhow::anyhow!("æœªçŸ¥é”™è¯¯")))
}

fn home_projects_file() -> PathBuf {
    let home = dirs::home_dir().unwrap_or_else(|| PathBuf::from("."));
    let data_dir = home.join(".acemcp").join("data");
    let _ = fs::create_dir_all(&data_dir);
    data_dir.join("projects.json")
}

/// è·å–é¡¹ç›®ç´¢å¼•çŠ¶æ€æ–‡ä»¶è·¯å¾„
fn home_projects_status_file() -> PathBuf {
    let home = dirs::home_dir().unwrap_or_else(|| PathBuf::from("."));
    let data_dir = home.join(".acemcp").join("data");
    let _ = fs::create_dir_all(&data_dir);
    data_dir.join("projects_status.json")
}

/// è¯»å–æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn load_projects_status() -> ProjectsIndexStatus {
    let status_path = home_projects_status_file();
    if status_path.exists() {
        let data = fs::read_to_string(&status_path).unwrap_or_default();
        serde_json::from_str(&data).unwrap_or_default()
    } else {
        ProjectsIndexStatus::default()
    }
}

/// ä¿å­˜æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn save_projects_status(status: &ProjectsIndexStatus) -> Result<()> {
    let status_path = home_projects_status_file();
    let data = serde_json::to_string_pretty(status)?;
    fs::write(status_path, data)?;
    Ok(())
}

/// æ›´æ–°æŒ‡å®šé¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn update_project_status<F>(project_root: &str, updater: F) -> Result<()>
where
    F: FnOnce(&mut ProjectIndexStatus),
{
    let mut all_status = load_projects_status();
    let normalized_root = PathBuf::from(project_root)
        .canonicalize()
        .unwrap_or_else(|_| PathBuf::from(project_root))
        .to_string_lossy()
        .replace('\\', "/");

    let project_status = all_status.projects
        .entry(normalized_root.clone())
        .or_insert_with(|| {
            let mut status = ProjectIndexStatus::default();
            status.project_root = normalized_root;
            status
        });

    updater(project_status);
    save_projects_status(&all_status)?;
    Ok(())
}

/// è·å–æŒ‡å®šé¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn get_project_status(project_root: &str) -> ProjectIndexStatus {
    let all_status = load_projects_status();
    let normalized_root = PathBuf::from(project_root)
        .canonicalize()
        .unwrap_or_else(|_| PathBuf::from(project_root))
        .to_string_lossy()
        .replace('\\', "/");

    all_status.projects.get(&normalized_root).cloned().unwrap_or_else(|| {
        let mut status = ProjectIndexStatus::default();
        status.project_root = normalized_root;
        status
    })
}

/// è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§ç¼–ç æ£€æµ‹
/// å°è¯•çš„ç¼–ç é¡ºåºï¼šutf-8, gbk (åŒ…å« gb2312), windows-1252 (åŒ…å« latin-1)
/// å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ™ä½¿ç”¨ utf-8 with errors='ignore'
fn read_file_with_encoding(path: &Path) -> Option<String> {
    let mut file = fs::File::open(path).ok()?;
    let mut buf = Vec::new();
    if file.read_to_end(&mut buf).is_err() {
        return None;
    }

    // å°è¯• utf-8
    let (decoded, _, had_errors) = UTF_8.decode(&buf);
    if !had_errors {
        return Some(decoded.into_owned());
    }

    // å°è¯• gbk
    let (decoded, _, had_errors) = GBK.decode(&buf);
    if !had_errors {
        log_debug!("æˆåŠŸä½¿ç”¨ GBK ç¼–ç è¯»å–æ–‡ä»¶: {:?}", path);
        return Some(decoded.into_owned());
    }

    // å°è¯• gb2312 (GBK æ˜¯ GB2312 çš„è¶…é›†ï¼Œå¯ä»¥å¤„ç† GB2312 ç¼–ç )
    // encoding_rs ä¸­æ²¡æœ‰å•ç‹¬çš„ GB2312ï¼Œä½¿ç”¨ GBK ä»£æ›¿
    // GBK å·²ç»åœ¨ä¸Šä¸€æ­¥å°è¯•è¿‡äº†ï¼Œè¿™é‡Œè·³è¿‡

    // å°è¯• latin-1 (WINDOWS_1252 æ˜¯ ISO-8859-1 çš„è¶…é›†ï¼Œå¯ä»¥å¤„ç†å¤§éƒ¨åˆ† latin-1 ç¼–ç )
    let (decoded, _, had_errors) = WINDOWS_1252.decode(&buf);
    if !had_errors {
        log_debug!("æˆåŠŸä½¿ç”¨ WINDOWS_1252 ç¼–ç è¯»å–æ–‡ä»¶: {:?}", path);
        return Some(decoded.into_owned());
    }

    // å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨ utf-8 with errors='ignore' (lossy è§£ç )
    let (decoded, _, _) = UTF_8.decode(&buf);
    log_debug!("ä½¿ç”¨ UTF-8 (lossy) è¯»å–æ–‡ä»¶ï¼Œéƒ¨åˆ†å­—ç¬¦å¯èƒ½ä¸¢å¤±: {:?}", path);
    Some(decoded.into_owned())
}

fn sha256_hex(path: &str, content: &str) -> String {
    let mut ctx = ShaContext::new(&SHA256);
    // å…ˆæ›´æ–°è·¯å¾„çš„å“ˆå¸Œï¼Œå†æ›´æ–°å†…å®¹çš„å“ˆå¸Œï¼Œä¸Pythonç‰ˆæœ¬ä¿æŒä¸€è‡´
    ctx.update(path.as_bytes());
    ctx.update(content.as_bytes());
    let digest = ctx.finish();
    hex::encode(digest.as_ref())
}

/// åˆ†å‰²æ–‡ä»¶å†…å®¹ä¸ºå¤šä¸ª blobï¼ˆå¦‚æœè¶…è¿‡æœ€å¤§è¡Œæ•°ï¼‰
/// ä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šchunk ç´¢å¼•ä» 1 å¼€å§‹
fn split_content(path: &str, content: &str, max_lines: usize) -> Vec<BlobItem> {
    let lines: Vec<&str> = content.split_inclusive('\n').collect();
    let total_lines = lines.len();
    
    // å¦‚æœæ–‡ä»¶åœ¨é™åˆ¶å†…ï¼Œè¿”å›å•ä¸ª blob
    if total_lines <= max_lines {
        return vec![BlobItem { path: path.to_string(), content: content.to_string() }];
    }

    // è®¡ç®—éœ€è¦çš„ chunk æ•°é‡
    let num_chunks = (total_lines + max_lines - 1) / max_lines;
    let mut blobs = Vec::new();

    // æŒ‰ chunk ç´¢å¼•åˆ†å‰²ï¼ˆä» 0 å¼€å§‹ï¼Œä½†æ˜¾ç¤ºæ—¶ä» 1 å¼€å§‹ï¼‰
    for chunk_idx in 0..num_chunks {
        let start_line = chunk_idx * max_lines;
        let end_line = usize::min(start_line + max_lines, total_lines);
        let chunk_lines = &lines[start_line..end_line];
        let chunk_content = chunk_lines.join("");

        // chunk ç¼–å·ä» 1 å¼€å§‹ï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        let chunk_path = format!("{}#chunk{}of{}", path, chunk_idx + 1, num_chunks);
        blobs.push(BlobItem { path: chunk_path, content: chunk_content });
    }

    blobs
}

/// æ„å»ºæ’é™¤æ¨¡å¼çš„ GlobSet
fn build_exclude_globset(exclude_patterns: &[String]) -> Result<GlobSet> {
    let mut builder = GlobSetBuilder::new();
    for pattern in exclude_patterns {
        // å°è¯•å°†æ¨¡å¼è½¬æ¢ä¸º Glob
        if let Ok(glob) = Glob::new(pattern) {
            builder.add(glob);
        } else {
            log_debug!("æ— æ•ˆçš„æ’é™¤æ¨¡å¼ï¼Œè·³è¿‡: {}", pattern);
        }
    }
    builder.build().map_err(|e| anyhow::anyhow!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥: {}", e))
}

/// æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤
/// ä½¿ç”¨ globset è¿›è¡Œå®Œæ•´çš„ fnmatch æ¨¡å¼åŒ¹é…ï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
/// Python ç‰ˆæœ¬ä½¿ç”¨ fnmatch.fnmatch æ£€æŸ¥è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†å’Œå®Œæ•´è·¯å¾„
fn should_exclude(path: &Path, root: &Path, exclude_globset: Option<&GlobSet>) -> bool {
    if exclude_globset.is_none() {
        return false;
    }
    let globset = exclude_globset.unwrap();

    // è·å–ç›¸å¯¹è·¯å¾„
    let rel = match path.strip_prefix(root) {
        Ok(rel) => rel,
        Err(_) => path,
    };

    // è½¬æ¢ä¸ºä½¿ç”¨æ­£æ–œæ çš„å­—ç¬¦ä¸²ï¼ˆç”¨äºåŒ¹é…ï¼‰
    let rel_forward = rel.to_string_lossy().replace('\\', "/");
    
    // æ£€æŸ¥å®Œæ•´ç›¸å¯¹è·¯å¾„ï¼ˆä¸ Python ç‰ˆæœ¬çš„ fnmatch(path_str, pattern) ä¸€è‡´ï¼‰
    if globset.is_match(&rel_forward) {
        return true;
    }

    // æ£€æŸ¥è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†ï¼ˆä¸ Python ç‰ˆæœ¬çš„ fnmatch(part, pattern) ä¸€è‡´ï¼‰
    for part in rel.iter() {
        if let Some(part_str) = part.to_str() {
            if globset.is_match(part_str) {
                return true;
            }
        }
    }

    false
}

fn build_gitignore(root: &Path) -> Option<Gitignore> {
    let mut builder = GitignoreBuilder::new(root);
    let gi_path = root.join(".gitignore");
    if gi_path.exists() {
        if builder.add(gi_path).is_some() { return None; }
        return match builder.build() { Ok(gi) => Some(gi), Err(_) => None };
    }
    None
}

fn collect_blobs(root: &str, text_exts: &[String], exclude_patterns: &[String], max_lines_per_blob: usize) -> anyhow::Result<Vec<BlobItem>> {
    let root_path = PathBuf::from(root);
    if !root_path.exists() { anyhow::bail!("é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: {}", root); }
    
    log_important!(info, "å¼€å§‹æ”¶é›†ä»£ç æ–‡ä»¶: æ ¹ç›®å½•={}, æ‰©å±•å={:?}, æ’é™¤æ¨¡å¼={:?}", root, text_exts, exclude_patterns);
    
    // æ„å»ºæ’é™¤æ¨¡å¼çš„ GlobSet
    let exclude_globset = if exclude_patterns.is_empty() {
        None
    } else {
        match build_exclude_globset(exclude_patterns) {
            Ok(gs) => Some(gs),
            Err(e) => {
                log_debug!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•åŒ¹é…: {}", e);
                None
            }
        }
    };
    
    let mut out = Vec::new();
    let gitignore = build_gitignore(&root_path);
    let mut dirs_stack = vec![root_path.clone()];
    let mut scanned_files = 0;
    let mut indexed_files = 0;
    let mut excluded_count = 0;
    
    while let Some(dir) = dirs_stack.pop() {
        let entries = match fs::read_dir(&dir) { Ok(e) => e, Err(_) => continue };
        for entry in entries.flatten() {
            let p = entry.path();
            
            // æ£€æŸ¥ .gitignore
            if let Some(gi) = &gitignore {
                if gi.matched_path_or_any_parents(&p, p.is_dir()).is_ignore() { continue; }
            }
            
            // æ£€æŸ¥æ’é™¤æ¨¡å¼
            if p.is_dir() {
                if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                    excluded_count += 1;
                    continue;
                }
                dirs_stack.push(p);
                continue;
            }
            
            scanned_files += 1;
            if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                excluded_count += 1;
                log_debug!("æ’é™¤æ–‡ä»¶: {:?}", p);
                continue;
            }
            
            // æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            let ext_ok = p.extension().and_then(|s| s.to_str()).map(|e| {
                let dot = format!(".{}", e).to_lowercase();
                text_exts.iter().any(|te| te.eq_ignore_ascii_case(&dot))
            }).unwrap_or(false);
            if !ext_ok { continue; }
            
            // è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨å¤šç¼–ç æ”¯æŒï¼‰
            let rel = p.strip_prefix(&root_path).unwrap_or(&p).to_string_lossy().replace('\\', "/");
            if let Some(content) = read_file_with_encoding(&p) {
                let parts = split_content(&rel, &content, max_lines_per_blob);
                let blob_count = parts.len();
                indexed_files += 1;
                out.extend(parts);
                log_important!(info, "ç´¢å¼•æ–‡ä»¶: path={}, content_length={}, blobs={}", rel, content.len(), blob_count);
            } else {
                log_debug!("æ— æ³•è¯»å–æ–‡ä»¶: {:?}", p);
            }
        }
    }
    
    log_important!(info, "æ–‡ä»¶æ”¶é›†å®Œæˆ: æ‰«ææ–‡ä»¶æ•°={}, ç´¢å¼•æ–‡ä»¶æ•°={}, ç”Ÿæˆblobsæ•°={}, æ’é™¤æ–‡ä»¶/ç›®å½•æ•°={}", scanned_files, indexed_files, out.len(), excluded_count);
    Ok(out)
}

/// åªæ‰§è¡Œç´¢å¼•æ›´æ–°ï¼Œä¸è¿›è¡Œæœç´¢
/// è¿”å›å€¼ï¼šæˆåŠŸä¸Šä¼ çš„ blob åç§°åˆ—è¡¨
pub(crate) async fn update_index(config: &AcemcpConfig, project_root_path: &str) -> anyhow::Result<Vec<String>> {
    let base_url = config.base_url.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® base_url"))?;
    // ä¸¥æ ¼æ ¡éªŒ base_url
    let has_scheme = base_url.starts_with("http://") || base_url.starts_with("https://");
    let has_host = base_url.trim().len() > "https://".len();
    if !has_scheme || !has_host { anyhow::bail!("æ— æ•ˆçš„ base_urlï¼Œè¯·å¡«å†™å®Œæ•´çš„ http(s)://host[:port] æ ¼å¼"); }
    let token = config.token.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® token"))?;
    let batch_size = config.batch_size.unwrap_or(10) as usize;
    let max_lines = config.max_lines_per_blob.unwrap_or(800) as usize;
    let text_exts = config.text_extensions.clone().unwrap_or_default();
    let exclude_patterns = config.exclude_patterns.clone().unwrap_or_default();

    // æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹ç´¢å¼•
    let _ = update_project_status(project_root_path, |status| {
        status.status = IndexStatus::Indexing;
        status.progress = 0;
    });

    // æ—¥å¿—ï¼šåŸºç¡€é…ç½®
    log_important!(info,
        "=== å¼€å§‹ç´¢å¼•ä»£ç åº“ ==="
    );
    log_important!(info,
        "Acemcpé…ç½®: base_url={}, batch_size={}, max_lines_per_blob={}, text_extsæ•°é‡={}, exclude_patternsæ•°é‡={}",
        base_url,
        batch_size,
        max_lines,
        text_exts.len(),
        exclude_patterns.len()
    );
    log_important!(info,
        "é¡¹ç›®è·¯å¾„: {}", project_root_path
    );

    // æ”¶é›† blobï¼ˆæ ¹æ®æ‰©å±•åä¸æ’é™¤è§„åˆ™ï¼Œç®€åŒ–ç‰ˆ .gitignore æ”¯æŒï¼‰
    log_important!(info, "å¼€å§‹æ”¶é›†ä»£ç æ–‡ä»¶...");
    let blobs = collect_blobs(project_root_path, &text_exts, &exclude_patterns, max_lines)?;
    if blobs.is_empty() {
        // æ›´æ–°çŠ¶æ€ï¼šå¤±è´¥
        let _ = update_project_status(project_root_path, |status| {
            status.status = IndexStatus::Failed;
            status.last_error = Some("æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡æœ¬æ–‡ä»¶".to_string());
            status.last_failure_time = Some(chrono::Utc::now());
        });
        anyhow::bail!("æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡æœ¬æ–‡ä»¶");
    }

    // æ›´æ–°çŠ¶æ€ï¼šæ–‡ä»¶æ”¶é›†å®Œæˆ
    let _ = update_project_status(project_root_path, |status| {
        status.total_files = blobs.len();
        status.progress = 20;
    });

    // åŠ è½½ projects.json
    let projects_path = home_projects_file();
    let mut projects: ProjectsFile = if projects_path.exists() {
        let data = fs::read_to_string(&projects_path).unwrap_or_default();
        serde_json::from_str(&data).unwrap_or_default()
    } else { ProjectsFile::default() };

    let normalized_root = PathBuf::from(project_root_path).canonicalize().unwrap_or_else(|_| PathBuf::from(project_root_path)).to_string_lossy().replace('\\', "/");
    let existing_blob_names: std::collections::HashSet<String> = projects.0.get(&normalized_root).cloned().unwrap_or_default().into_iter().collect();

    // è®¡ç®—æ‰€æœ‰ blob çš„å“ˆå¸Œå€¼ï¼Œå»ºç«‹å“ˆå¸Œåˆ° blob çš„æ˜ å°„
    let mut blob_hash_map: std::collections::HashMap<String, BlobItem> = std::collections::HashMap::new();
    for blob in &blobs {
        let hash = sha256_hex(&blob.path, &blob.content);
        blob_hash_map.insert(hash.clone(), blob.clone());
    }

    // åˆ†ç¦»å·²å­˜åœ¨å’Œæ–°å¢åŠ çš„ blobï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    let all_blob_hashes: std::collections::HashSet<String> = blob_hash_map.keys().cloned().collect();
    let existing_hashes: std::collections::HashSet<String> = all_blob_hashes.intersection(&existing_blob_names).cloned().collect();
    let new_hashes: std::collections::HashSet<String> = all_blob_hashes.difference(&existing_blob_names).cloned().collect();

    // éœ€è¦ä¸Šä¼ çš„æ–° blob
    let new_blobs: Vec<BlobItem> = new_hashes.iter().filter_map(|h| blob_hash_map.get(h).cloned()).collect();

    log_important!(info,
        "=== ç´¢å¼•ç»Ÿè®¡ ==="
    );
    log_important!(info,
        "æ”¶é›†åˆ°blobsæ€»æ•°: {}, æ—¢æœ‰blobs: {}, æ–°å¢blobs: {}, éœ€è¦ä¸Šä¼ : {}",
        blobs.len(),
        existing_hashes.len(),
        new_hashes.len(),
        new_blobs.len()
    );

    let client = Client::new();

    // æ‰¹é‡ä¸Šä¼ æ–°å¢ blobs
    let mut uploaded_names: Vec<String> = Vec::new();
    let mut failed_batches: Vec<usize> = Vec::new();
    
    if !new_blobs.is_empty() {
        let total_batches = (new_blobs.len() + batch_size - 1) / batch_size;
        log_important!(info,
            "=== å¼€å§‹æ‰¹é‡ä¸Šä¼ ä»£ç ç´¢å¼• ==="
        );
        log_important!(info,
            "ç›®æ ‡ç«¯ç‚¹: {}/batch-upload, æ€»æ‰¹æ¬¡: {}, æ¯æ‰¹ä¸Šé™: {}, æ€»blobs: {}",
            base_url,
            total_batches,
            batch_size,
            new_blobs.len()
        );
        
        for i in 0..total_batches {
            let start = i * batch_size;
            let end = usize::min(start + batch_size, new_blobs.len());
            let batch = &new_blobs[start..end];
            let url = format!("{}/batch-upload", base_url);
            
            log_important!(info,
                "ä¸Šä¼ æ‰¹æ¬¡ {}/{}: url={}, blobs={}",
                i + 1,
                total_batches,
                url,
                batch.len()
            );
            
            // è¯¦ç»†è®°å½•æ¯ä¸ª blob çš„ä¿¡æ¯
            for (idx, blob) in batch.iter().enumerate() {
                log_important!(info,
                    "  æ‰¹æ¬¡ {} - Blob {}/{}: path={}, content_length={}",
                    i + 1,
                    idx + 1,
                    batch.len(),
                    blob.path,
                    blob.content.len()
                );
            }
            
            let payload = serde_json::json!({"blobs": batch});
            log_important!(info, "æ‰¹æ¬¡è½½è·å¤§å°: {} å­—èŠ‚", payload.to_string().len());
            
            match retry_request(|| async {
                let r = client
                    .post(&url)
                    .header(AUTHORIZATION, format!("Bearer {}", token))
                    .header(CONTENT_TYPE, "application/json")
                    .json(&payload)
                    .send()
                    .await?;
                
                let status = r.status();
                log_important!(info, "HTTPå“åº”çŠ¶æ€: {}", status);
                
                if !status.is_success() {
                    let body = r.text().await.unwrap_or_default();
                    anyhow::bail!("HTTP {} {}", status, body);
                }
                
                let v: serde_json::Value = r.json().await?;
                log_important!(info, "å“åº”æ•°æ®: {}", serde_json::to_string_pretty(&v).unwrap_or_default());
                Ok(v)
            }, 3, 1.0).await {
                Ok(value) => {
                    if let Some(arr) = value.get("blob_names").and_then(|v| v.as_array()) {
                        let mut batch_names: Vec<String> = Vec::new();
                        for v in arr { 
                            if let Some(s) = v.as_str() { 
                                batch_names.push(s.to_string()); 
                            }
                        }
                        
                        if batch_names.is_empty() {
                            log_important!(info, "æ‰¹æ¬¡ {} è¿”å›äº†ç©ºçš„blobåç§°åˆ—è¡¨", i + 1);
                            failed_batches.push(i + 1);
                        } else {
                            uploaded_names.extend(batch_names.clone());
                            log_important!(info, "æ‰¹æ¬¡ {} ä¸Šä¼ æˆåŠŸï¼Œè·å¾— {} ä¸ªblobåç§°", i + 1, batch_names.len());
                            // è¯¦ç»†è®°å½•æ¯ä¸ªä¸Šä¼ æˆåŠŸçš„ blob åç§°
                            for (idx, name) in batch_names.iter().enumerate() {
                                log_important!(info, "  æ‰¹æ¬¡ {} - ä¸Šä¼ æˆåŠŸ Blob {}/{}: name={}", i + 1, idx + 1, batch_names.len(), name);
                            }
                        }
                    } else {
                        log_important!(info, "æ‰¹æ¬¡ {} å“åº”ä¸­ç¼ºå°‘blob_nameså­—æ®µ", i + 1);
                        failed_batches.push(i + 1);
                    }
                }
                Err(e) => {
                    log_important!(info, "æ‰¹æ¬¡ {} ä¸Šä¼ å¤±è´¥: {}", i + 1, e);
                    failed_batches.push(i + 1);
                }
            }
        }
        
        // ä¸Šä¼ ç»“æœæ€»ç»“
        log_important!(info,
            "=== ä¸Šä¼ ç»“æœæ€»ç»“ ==="
        );
        if !failed_batches.is_empty() {
            log_important!(info, "ä¸Šä¼ å®Œæˆï¼Œä½†æœ‰å¤±è´¥çš„æ‰¹æ¬¡: {:?}, æˆåŠŸä¸Šä¼ blobs: {}", failed_batches, uploaded_names.len());
        } else {
            log_important!(info, "æ‰€æœ‰æ‰¹æ¬¡ä¸Šä¼ æˆåŠŸï¼Œå…±ä¸Šä¼  {} ä¸ªblobs", uploaded_names.len());
        }
    } else {
        log_important!(info, "æ²¡æœ‰æ–°çš„blobéœ€è¦ä¸Šä¼ ï¼Œä½¿ç”¨å·²æœ‰ç´¢å¼•");
    }

    // åˆå¹¶å¹¶ä¿å­˜ projects.jsonï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    // åªä¿ç•™å½“å‰é¡¹ç›®ä¸­ä»ç„¶å­˜åœ¨çš„ blob çš„å“ˆå¸Œå€¼ï¼ˆè‡ªåŠ¨åˆ é™¤å·²åˆ é™¤çš„ blobï¼‰
    let all_blob_names: Vec<String> = existing_hashes.into_iter().chain(uploaded_names.into_iter()).collect();
    projects.0.insert(normalized_root.clone(), all_blob_names.clone());
    if let Ok(s) = serde_json::to_string_pretty(&projects) { let _ = fs::write(projects_path, s); }

    // ä½¿ç”¨åˆå¹¶åçš„ blob_namesï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    let blob_names = all_blob_names;
    if blob_names.is_empty() {
        log_important!(info, "ç´¢å¼•åæœªæ‰¾åˆ° blobsï¼Œé¡¹ç›®è·¯å¾„: {}", normalized_root);
        // æ›´æ–°çŠ¶æ€ï¼šå¤±è´¥
        let _ = update_project_status(project_root_path, |status| {
            status.status = IndexStatus::Failed;
            status.last_error = Some("ç´¢å¼•åæœªæ‰¾åˆ° blobs".to_string());
            status.last_failure_time = Some(chrono::Utc::now());
        });
        anyhow::bail!("ç´¢å¼•åæœªæ‰¾åˆ° blobs");
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯é¦–æ¬¡æˆåŠŸç´¢å¼•ï¼ˆç”¨äº ji é›†æˆï¼‰
    let is_first_success = {
        let status = get_project_status(project_root_path);
        status.last_success_time.is_none()
    };

    // æ›´æ–°çŠ¶æ€ï¼šç´¢å¼•æˆåŠŸå®Œæˆ
    let _ = update_project_status(project_root_path, |status| {
        status.status = IndexStatus::Synced;
        status.progress = 100;
        status.indexed_files = blobs.len();
        status.pending_files = 0;
        status.last_success_time = Some(chrono::Utc::now());
        status.last_error = None;
    });

    // é¦–æ¬¡æˆåŠŸç´¢å¼•æ—¶ï¼Œå†™å…¥ ji è®°å¿†
    if is_first_success {
        let _ = write_index_memory_to_ji(project_root_path, config);
    }

    log_important!(info, "ç´¢å¼•æ›´æ–°å®Œæˆï¼Œå…± {} ä¸ª blobs", blob_names.len());
    Ok(blob_names)
}

/// å°†ç´¢å¼•é…ç½®ä¿¡æ¯å†™å…¥ jiï¼ˆè®°å¿†ï¼‰å·¥å…·
fn write_index_memory_to_ji(project_root_path: &str, config: &AcemcpConfig) {
    use super::super::memory::MemoryManager;
    use super::super::memory::MemoryCategory;

    // åˆ›å»ºè®°å¿†ç®¡ç†å™¨
    let manager = match MemoryManager::new(project_root_path) {
        Ok(m) => m,
        Err(e) => {
            log_debug!("åˆ›å»ºè®°å¿†ç®¡ç†å™¨å¤±è´¥ï¼ˆä¸å½±å“ç´¢å¼•ï¼‰: {}", e);
            return;
        }
    };

    // æ„å»ºè®°å¿†å†…å®¹
    let text_exts = config.text_extensions.clone().unwrap_or_default();
    let exclude_patterns = config.exclude_patterns.clone().unwrap_or_default();
    let batch_size = config.batch_size.unwrap_or(10);
    let max_lines = config.max_lines_per_blob.unwrap_or(800);

    let memory_content = format!(
        "acemcp ä»£ç ç´¢å¼•å·²å¯ç”¨ - é…ç½®æ‘˜è¦: æ–‡ä»¶æ‰©å±•å={:?}, æ’é™¤æ¨¡å¼={:?}, æ‰¹æ¬¡å¤§å°={}, æœ€å¤§è¡Œæ•°/å—={}",
        text_exts, exclude_patterns, batch_size, max_lines
    );

    // å†™å…¥è®°å¿†
    match manager.add_memory(&memory_content, MemoryCategory::Context) {
        Ok(id) => {
            log_important!(info, "å·²å°†ç´¢å¼•é…ç½®å†™å…¥ ji è®°å¿†: id={}", id);
        }
        Err(e) => {
            log_debug!("å†™å…¥ ji è®°å¿†å¤±è´¥ï¼ˆä¸å½±å“ç´¢å¼•ï¼‰: {}", e);
        }
    }
}

/// åªæ‰§è¡Œæœç´¢ï¼Œä¸è§¦å‘ç´¢å¼•
/// ä½¿ç”¨å·²æœ‰çš„ç´¢å¼•æ•°æ®è¿›è¡Œæœç´¢
async fn search_only(config: &AcemcpConfig, project_root_path: &str, query: &str) -> anyhow::Result<String> {
    let base_url = config.base_url.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® base_url"))?;
    let token = config.token.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® token"))?;

    // ä» projects.json è¯»å–å·²æœ‰çš„ blob åç§°
    let projects_path = home_projects_file();
    let projects: ProjectsFile = if projects_path.exists() {
        let data = fs::read_to_string(&projects_path).unwrap_or_default();
        serde_json::from_str(&data).unwrap_or_default()
    } else {
        ProjectsFile::default()
    };

    let normalized_root = PathBuf::from(project_root_path)
        .canonicalize()
        .unwrap_or_else(|_| PathBuf::from(project_root_path))
        .to_string_lossy()
        .replace('\\', "/");

    let blob_names = projects.0.get(&normalized_root).cloned().unwrap_or_default();

    if blob_names.is_empty() {
        anyhow::bail!("é¡¹ç›®å°šæœªç´¢å¼•æˆ–ç´¢å¼•ä¸ºç©ºï¼Œè¯·å…ˆæ‰§è¡Œç´¢å¼•æ“ä½œ");
    }

    // å‘èµ·æ£€ç´¢
    log_important!(info,
        "=== å¼€å§‹ä»£ç æ£€ç´¢ï¼ˆä»…æœç´¢æ¨¡å¼ï¼‰ ==="
    );
    let search_url = format!("{}/agents/codebase-retrieval", base_url);
    log_important!(info, "æ£€ç´¢è¯·æ±‚: url={}, ä½¿ç”¨blobsæ•°é‡={}, æŸ¥è¯¢å†…å®¹={}", search_url, blob_names.len(), query);

    let payload = serde_json::json!({
        "information_request": query,
        "blobs": {"checkpoint_id": serde_json::Value::Null, "added_blobs": blob_names, "deleted_blobs": []},
        "dialog": [],
        "max_output_length": 0,
        "disable_codebase_retrieval": false,
        "enable_commit_retrieval": false,
    });

    log_important!(info, "æ£€ç´¢è½½è·å¤§å°: {} å­—èŠ‚", payload.to_string().len());

    let client = Client::new();
    let value: serde_json::Value = retry_request(|| async {
        let r = client
            .post(&search_url)
            .header(AUTHORIZATION, format!("Bearer {}", token))
            .header(CONTENT_TYPE, "application/json")
            .json(&payload)
            .send()
            .await?;

        let status = r.status();
        log_important!(info, "æ£€ç´¢è¯·æ±‚HTTPå“åº”çŠ¶æ€: {}", status);

        if !status.is_success() {
            let body = r.text().await.unwrap_or_default();
            anyhow::bail!("HTTP {} {}", status, body);
        }

        let v: serde_json::Value = r.json().await?;
        log_important!(info, "æ£€ç´¢å“åº”æ•°æ®: {}", serde_json::to_string_pretty(&v).unwrap_or_default());
        Ok(v)
    }, 3, 2.0).await?;

    let text = value
        .get("formatted_retrieval")
        .and_then(|v| v.as_str())
        .unwrap_or("")
        .to_string();

    if text.is_empty() {
        log_important!(info, "æœç´¢è¿”å›ç©ºç»“æœ");
        Ok("No relevant code context found for your query.".to_string())
    } else {
        log_important!(info, "æœç´¢æˆåŠŸï¼Œè¿”å›æ–‡æœ¬é•¿åº¦: {}", text.len());
        Ok(text)
    }
}
